{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Panos\\.conda\\envs\\Marlowe\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,auc,roc_curve\n",
    "import clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for cleaning Shakespeare plays, using the custom clean module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanShakespeareText(filePath):\n",
    "    with open(filePath) as file:\n",
    "        lines = file.readlines()\n",
    "        file.close()\n",
    "    text=[]\n",
    "\n",
    "    for line in lines:\n",
    "        if line =='\\n':\n",
    "            continue\n",
    "        \n",
    "        line=clean.removeSpeakerName(line) #remove speaker's name from  each line\n",
    "        line=clean.removeLinesBasedOnWords(['ACT', 'SCENE'],line) # removing lines with the words ACTS and Scenes\n",
    "        line=clean.removeWords(['1','2','3','4','5','6','7','8','9'],line)\n",
    "        line=clean.removeLinesBasedOnWords(['Exit'],line)\n",
    "        line=clean.removeLinesBasedOnWords(['Enter'],line)\n",
    "        line=clean.remove_words_in_brackets(line)\n",
    "        line=clean.removeWhitespace(line)\n",
    "        text.append(line)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for the creation of the clean plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFilesinPath(playPath,cleanFilesPath):\n",
    "    for play in os.scandir(playPath):\n",
    "        if play.is_file():\n",
    "            print((\" cleaning  \") + (play.name))\n",
    "            cleanedPlay=cleanShakespeareText(play.path)\n",
    "            \n",
    "            with open(cleanFilesPath+play.name.removesuffix('.txt')+'Cleaned'+'.txt', 'w') as cleanedFile:\n",
    "                \n",
    "                cleanedFile.write(\"\\n\".join(str(item) for item in cleanedPlay))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OriginalShakespearePath='./Corpus/Shakespeare/'\n",
    "CleanShakespearePath='./Corpus/Shakespeare/CleanedPlays/'\n",
    "cleanFilesinPath(OriginalShakespearePath,CleanShakespearePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for the import of the selected plays from each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def importPlaysinCorpus(CorpusPath,Author):\n",
    "    corpus=pd.DataFrame()\n",
    "    for play in os.scandir(CorpusPath):\n",
    "        if play.is_file():\n",
    "            print((\" importing  \") + (play.path) + (\" to corpus\"))\n",
    "            newplay=pd.read_csv(play.path, delimiter='\\r', header=None, names=['sentence_source', 'author', 'play'])\n",
    "            newplay[['author']]=Author\n",
    "            if 'Cleaned' in play.path:\n",
    "                newplay[['play']]=os.path.basename(play.path).removesuffix('Cleaned.txt')\n",
    "            else:\n",
    "                newplay[['play']]=os.path.basename(play.path).removesuffix('.txt')\n",
    "            corpus=pd.concat([corpus, newplay], axis = 0,join='outer')\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " importing  ./Corpus/Marlowe/Dido.txt to corpus\n",
      " importing  ./Corpus/Marlowe/DrFaustus.txt to corpus\n",
      " importing  ./Corpus/Marlowe/EdwardII.txt to corpus\n",
      " importing  ./Corpus/Marlowe/JewOfMalta.txt to corpus\n",
      " importing  ./Corpus/Marlowe/Tamburlaine1.txt to corpus\n",
      " importing  ./Corpus/Marlowe/Tamburlaine2.txt to corpus\n",
      " importing  ./Corpus/Shakespeare/CleanedPlays/AnthonyCleopatraCleaned.txt to corpus\n",
      " importing  ./Corpus/Shakespeare/CleanedPlays/HenryVIIICleaned.txt to corpus\n",
      " importing  ./Corpus/Shakespeare/CleanedPlays/HenryVCleaned.txt to corpus\n",
      " importing  ./Corpus/Shakespeare/CleanedPlays/MacbethCleaned.txt to corpus\n",
      " importing  ./Corpus/Shakespeare/CleanedPlays/RichardIIICleaned.txt to corpus\n",
      " importing  ./Corpus/Shakespeare/CleanedPlays/HamletCleaned.txt to corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Panos\\AppData\\Local\\Temp\\ipykernel_13820\\3394905571.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  projectCorpus=projectCorpus.append(importPlaysinCorpus(ShakespearePath,'Shakespeare'))\n"
     ]
    }
   ],
   "source": [
    "projectCorpus=pd.DataFrame()\n",
    "MarlowePath='./Corpus/Marlowe/'\n",
    "ShakespearePath='./Corpus/Shakespeare/CleanedPlays/'\n",
    "\n",
    "projectCorpus=importPlaysinCorpus(MarlowePath,'Marlowe')\n",
    "projectCorpus=projectCorpus.append(importPlaysinCorpus(ShakespearePath,'Shakespeare'))\n",
    "projectCorpus['sentence_source']=projectCorpus['sentence_source'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marlowe median rows  2495.5\n",
      "Shakespeare median rows  3578.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Marlowe median rows \",  projectCorpus.loc[projectCorpus['author'] == 'Marlowe'].play.value_counts().median())\n",
    "print(\"Shakespeare median rows \",  projectCorpus.loc[projectCorpus['author'] == 'Shakespeare'].play.value_counts().median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a sample of each play based on Marlowe's plays line median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewShakesepareCorpus=pd.DataFrame()\n",
    "MarloweMean=projectCorpus.loc[projectCorpus['author'] == 'Marlowe'].play.value_counts().mean()\n",
    "for play in projectCorpus.loc[projectCorpus['author'] == 'Shakespeare'].play.unique():\n",
    "    selectedPlay=projectCorpus.loc[projectCorpus['play'] == play]\n",
    "    if selectedPlay.value_counts().sum() > MarloweMean:\n",
    "        playSample = selectedPlay.sample(int(MarloweMean))\n",
    "        NewShakesepareCorpus=pd.concat([NewShakesepareCorpus, playSample], axis = 0,join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>author</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>unsifted in such perilous circumstance.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>Hamlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>let’s away to him.exeunt.</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>DrFaustus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>did you attempt his rescue, edmund</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>EdwardII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>whereon his brains still beating puts him thus</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>Hamlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>than live in infamy under such a king.</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>EdwardII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>ay, by heaven, my lord.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>Hamlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>his horses go about.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>Macbeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>thought thy bride-bed to have deck’d, sweet maid,</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>Hamlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>which we have not done neither; that,  fear,</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenryVIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>have knit again, and fleet, threat'ning most s...</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>AnthonyCleopatra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>this friar; he was ready to leap off ere the h...</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>JewOfMalta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>tis like enough, for since he was exiled,</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>EdwardII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>well use that trick no more, i would advise you.</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>DrFaustus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>aye me, see where he comes, and they with him,</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>EdwardII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>give me the letters, daughter, do you hear?</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>JewOfMalta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>let him appear.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>AnthonyCleopatra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>is this the honour they do one another?</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenryVIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>o dreary engines of my loathed sight,</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>Tamburlaine1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>and from my heart’s love  do thank thee for it.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>RichardIII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>groan for this grief, behold how thou art maim...</td>\n",
       "      <td>Marlowe</td>\n",
       "      <td>EdwardII</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentence_source       author  \\\n",
       "581             unsifted in such perilous circumstance.  Shakespeare   \n",
       "1233                          let’s away to him.exeunt.      Marlowe   \n",
       "2612                did you attempt his rescue, edmund       Marlowe   \n",
       "1790     whereon his brains still beating puts him thus  Shakespeare   \n",
       "1656             than live in infamy under such a king.      Marlowe   \n",
       "853                             ay, by heaven, my lord.  Shakespeare   \n",
       "1147                               his horses go about.  Shakespeare   \n",
       "3404  thought thy bride-bed to have deck’d, sweet maid,  Shakespeare   \n",
       "3438       which we have not done neither; that,  fear,  Shakespeare   \n",
       "2429  have knit again, and fleet, threat'ning most s...  Shakespeare   \n",
       "1864  this friar; he was ready to leap off ere the h...      Marlowe   \n",
       "792          tis like enough, for since he was exiled,       Marlowe   \n",
       "909    well use that trick no more, i would advise you.      Marlowe   \n",
       "2805   aye me, see where he comes, and they with him,        Marlowe   \n",
       "1100        give me the letters, daughter, do you hear?      Marlowe   \n",
       "204                                     let him appear.  Shakespeare   \n",
       "3012            is this the honour they do one another?  Shakespeare   \n",
       "2221             o dreary engines of my loathed sight,       Marlowe   \n",
       "2900    and from my heart’s love  do thank thee for it.  Shakespeare   \n",
       "1663  groan for this grief, behold how thou art maim...      Marlowe   \n",
       "\n",
       "                  play  \n",
       "581             Hamlet  \n",
       "1233         DrFaustus  \n",
       "2612          EdwardII  \n",
       "1790            Hamlet  \n",
       "1656          EdwardII  \n",
       "853             Hamlet  \n",
       "1147           Macbeth  \n",
       "3404            Hamlet  \n",
       "3438         HenryVIII  \n",
       "2429  AnthonyCleopatra  \n",
       "1864        JewOfMalta  \n",
       "792           EdwardII  \n",
       "909          DrFaustus  \n",
       "2805          EdwardII  \n",
       "1100        JewOfMalta  \n",
       "204   AnthonyCleopatra  \n",
       "3012         HenryVIII  \n",
       "2221      Tamburlaine1  \n",
       "2900        RichardIII  \n",
       "1663          EdwardII  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewProjectCorpus=pd.DataFrame()\n",
    "NewProjectCorpus=projectCorpus.loc[projectCorpus['author'] == 'Marlowe']\n",
    "NewProjectCorpus=pd.concat([NewProjectCorpus, NewShakesepareCorpus], axis = 0,join='outer')\n",
    "NewProjectCorpus.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to count words in each play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsPerPlay(corpus):\n",
    "    columns=['Play', 'Words Sum', 'Author']\n",
    "    PlayList=[]\n",
    "    for Play in corpus['play'].unique():\n",
    "            PlayInLoop=(corpus.loc[corpus['play'] == Play])\n",
    "            PlaySum = sum(PlayInLoop['sentence_source'].str.count('\\w+'))\n",
    "            PlayName = Play\n",
    "            PlayAuthor = PlayInLoop['author'].unique()[0]\n",
    "            PlayList.append([PlayName,PlaySum,PlayAuthor])\n",
    "            \n",
    "    WordsPerPlay=pd.DataFrame(PlayList, columns=columns)\n",
    "    return WordsPerPlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Corpus:\n",
      "                 Play  Words Sum       Author\n",
      "0               Dido      14003      Marlowe\n",
      "1          DrFaustus      12040      Marlowe\n",
      "2           EdwardII      21164      Marlowe\n",
      "3         JewOfMalta      19328      Marlowe\n",
      "4       Tamburlaine1      17666      Marlowe\n",
      "5       Tamburlaine2      17921      Marlowe\n",
      "6   AnthonyCleopatra      24163  Shakespeare\n",
      "7          HenryVIII      24230  Shakespeare\n",
      "8             HenryV      28687  Shakespeare\n",
      "9            Macbeth      16859  Shakespeare\n",
      "10        RichardIII      30886  Shakespeare\n",
      "11            Hamlet      29958  Shakespeare \n",
      " New Corpus:\n",
      "                 Play  Words Sum       Author\n",
      "0               Dido      14003      Marlowe\n",
      "1          DrFaustus      12040      Marlowe\n",
      "2           EdwardII      21164      Marlowe\n",
      "3         JewOfMalta      19328      Marlowe\n",
      "4       Tamburlaine1      17666      Marlowe\n",
      "5       Tamburlaine2      17921      Marlowe\n",
      "6   AnthonyCleopatra      14000  Shakespeare\n",
      "7          HenryVIII      15208  Shakespeare\n",
      "8             HenryV      18819  Shakespeare\n",
      "9            Macbeth      15310  Shakespeare\n",
      "10        RichardIII      16707  Shakespeare\n",
      "11            Hamlet      16729  Shakespeare\n",
      "Old Corpus Mean:\n",
      " 21408.75 \n",
      " New Corpus Mean:\n",
      " 16574.583333333332\n"
     ]
    }
   ],
   "source": [
    "corpusStats=wordsPerPlay(projectCorpus)\n",
    "newCorpusStats=wordsPerPlay(NewProjectCorpus)\n",
    "print(\"Old Corpus:\\n\",corpusStats,\"\\n\",\"New Corpus:\\n\",newCorpusStats)\n",
    "print(\"Old Corpus Mean:\\n\",corpusStats['Words Sum'].mean(),\"\\n\",\"New Corpus Mean:\\n\",newCorpusStats['Words Sum'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shakespeare corpus mean before sampling 25797.166666666668 Shakespeare corpus mean after sampling 16128.833333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Shakespeare corpus mean before sampling\",corpusStats.loc[corpusStats['Author'] == 'Shakespeare']['Words Sum'].mean(),\"Shakespeare corpus mean after sampling\",newCorpusStats.loc[corpusStats['Author'] == 'Shakespeare']['Words Sum'].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p1> Preparing the data for tokenization, splitting them and  data </p1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\Panos\\.conda\\envs\\Marlowe\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Panos\\AppData\\Local\\Temp\\ipykernel_13820\\3020684055.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "C:\\Users\\Panos\\AppData\\Local\\Temp\\ipykernel_13820\\3020684055.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading the pre-trained BERT model and tokenizer\n",
    "model = 'bert-large-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model)\n",
    "MarShpeare = BertForSequenceClassification.from_pretrained(model, num_labels=1)\n",
    "\n",
    "input_ids = [tokenizer.encode(sent, add_special_tokens=True,max_length=100,pad_to_max_length=True) for sent in NewProjectCorpus]\n",
    "# Preparing the data\n",
    "\n",
    "X = [str(i) for i in NewProjectCorpus['sentence_source'].values]       # comma separate the sentences in the pandas column 'sentence_source'\n",
    "\n",
    "NewProjectCorpus['author'].replace(['Marlowe','Shakespeare'],[0,1],inplace=True)       # replace authors with numbers in the pandas column 'author' as tensors accept numerical values only\n",
    "\n",
    "y = [float(i) for i in NewProjectCorpus['author'].values]                # comma separate the integers representing the authors, the backward function expects a float\n",
    "\n",
    "# Tokenize and format the input sentences\n",
    "X_tokenized = tokenizer(X, padding=True, truncation=True, max_length=100, return_tensors='pt')\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tokenized['input_ids'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "# Create the DataLoader for training and testing\n",
    "BatchSize = 16\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, shuffle=True,batch_size=BatchSize)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, shuffle=True,batch_size=BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(MarShpeare.parameters())\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Average Training Loss: 0.32499487718694675\n",
      "Epoch 2/7, Average Training Loss: 0.3074251179118783\n",
      "Epoch 3/7, Average Training Loss: 0.2864092650617846\n",
      "Epoch 4/7, Average Training Loss: 0.2979120805939741\n",
      "Epoch 5/7, Average Training Loss: 0.2911657956210491\n",
      "Epoch 6/7, Average Training Loss: 0.2927288159922762\n",
      "Epoch 7/7, Average Training Loss: 0.2962071697795327\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 7 #5 epochs seem to work best\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use nvidia cuda 12.1 -> 12.2 is not supported yet!\n",
    "MarShpeare.to(device)\n",
    "MarShpeare.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = MarShpeare(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_train_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5088393543428132\n",
      "F1 score: 0.337238920020377\n"
     ]
    }
   ],
   "source": [
    "MarShpeare.eval()\n",
    "preds = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "\n",
    "        outputs = MarShpeare(input_ids)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        preds.extend(predicted_labels.tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, preds)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "f1 = f1_score(true_labels, preds, average='macro') \n",
    "print(f\"F1 score: {f1}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(true_labels, preds, pos_label=2)\n",
    "AUC = auc(fpr, tpr)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SavePath='c:/temp/MarSpheare'\n",
    "MarShpeare.save_pretrained('c:/temp/MarSpheare')\n",
    "tokenizer.save_pretrained('c:/temp/MarSpheare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p2>Evaluating the model</p2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestPath='./Corpus/Unseen/'\n",
    "CleanTestPath='./Corpus/Unseen/Cleaned/'\n",
    "\n",
    "\n",
    "#cleanFilesinPath(TestPath,CleanTestPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " importing  ./Corpus/Unseen/Cleaned/HenrVIPart1Cleaned.txt to corpus\n",
      " importing  ./Corpus/Unseen/Cleaned/HenrVIPart3Cleaned.txt to corpus\n",
      " importing  ./Corpus/Unseen/Cleaned/HenrVIPart2Cleaned.txt to corpus\n"
     ]
    }
   ],
   "source": [
    "testCorpus=pd.DataFrame()\n",
    "\n",
    "testCorpus=importPlaysinCorpus(CleanTestPath,'Shakespeare')\n",
    "testCorpus['sentence_source']=testCorpus['sentence_source'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>author</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>but is your grace dead, my lord of somerset?</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>you should leave me at the white hart in south...</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>begin your suits anew, and sue to him.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>tends to god's glory and my country's weal.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>under the wings of our protector’s grace,</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>clarence, excuse me to the king my brother.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>and we are grac'd with wreaths of victory.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>marriage is a matter of more worth</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>and  am louted by a traitor villain</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>him so much that he is drunk; and he enters wi...</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>invite my lords of salisbury and warwick</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>henceforth  will not have to do with pity.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>ay, for if edward repossess the crown,</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>full well hath clifford play'd the orator,</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>go, take their bodies hence.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>would break a thousand oaths to reign one year.</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>our hap is lost, our hope but sad despair;</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>yet let us watch the haughty cardinal;</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>alas, sir,  am but a poor petitioner of our wh...</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>and thought thee happy when  shook my head?</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>HenrVIPart2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentence_source       author  \\\n",
       "23         but is your grace dead, my lord of somerset?  Shakespeare   \n",
       "2560  you should leave me at the white hart in south...  Shakespeare   \n",
       "395              begin your suits anew, and sue to him.  Shakespeare   \n",
       "2332        tends to god's glory and my country's weal.  Shakespeare   \n",
       "394           under the wings of our protector’s grace,  Shakespeare   \n",
       "2878        clarence, excuse me to the king my brother.  Shakespeare   \n",
       "2716         and we are grac'd with wreaths of victory.  Shakespeare   \n",
       "2846                 marriage is a matter of more worth  Shakespeare   \n",
       "1988                and  am louted by a traitor villain  Shakespeare   \n",
       "1015  him so much that he is drunk; and he enters wi...  Shakespeare   \n",
       "659            invite my lords of salisbury and warwick  Shakespeare   \n",
       "3000         henceforth  will not have to do with pity.  Shakespeare   \n",
       "2369             ay, for if edward repossess the crown,  Shakespeare   \n",
       "865          full well hath clifford play'd the orator,  Shakespeare   \n",
       "2291                       go, take their bodies hence.  Shakespeare   \n",
       "309     would break a thousand oaths to reign one year.  Shakespeare   \n",
       "1013         our hap is lost, our hope but sad despair;  Shakespeare   \n",
       "172              yet let us watch the haughty cardinal;  Shakespeare   \n",
       "383   alas, sir,  am but a poor petitioner of our wh...  Shakespeare   \n",
       "2066        and thought thee happy when  shook my head?  Shakespeare   \n",
       "\n",
       "             play  \n",
       "23    HenrVIPart3  \n",
       "2560  HenrVIPart2  \n",
       "395   HenrVIPart2  \n",
       "2332  HenrVIPart1  \n",
       "394   HenrVIPart2  \n",
       "2878  HenrVIPart3  \n",
       "2716  HenrVIPart3  \n",
       "2846  HenrVIPart1  \n",
       "1988  HenrVIPart1  \n",
       "1015  HenrVIPart2  \n",
       "659   HenrVIPart2  \n",
       "3000  HenrVIPart2  \n",
       "2369  HenrVIPart3  \n",
       "865   HenrVIPart3  \n",
       "2291  HenrVIPart1  \n",
       "309   HenrVIPart3  \n",
       "1013  HenrVIPart3  \n",
       "172   HenrVIPart2  \n",
       "383   HenrVIPart2  \n",
       "2066  HenrVIPart2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCorpus.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'c:/temp/MarSpheare'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m testCorpus[\u001b[39m'\u001b[39m\u001b[39msentence_source\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues]       \u001b[39m# comma separate the sentences in the pandas column 'sentence_source'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(SavePath)\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model)\n\u001b[0;32m      4\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# use nvidia cuda 12.1 -> 12.2 is not supported yet!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Panos\\.conda\\envs\\Marlowe\\lib\\site-packages\\torch\\serialization.py:988\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    986\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 988\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    989\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    990\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    992\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    993\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Panos\\.conda\\envs\\Marlowe\\lib\\site-packages\\torch\\serialization.py:437\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    436\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 437\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    438\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Panos\\.conda\\envs\\Marlowe\\lib\\site-packages\\torch\\serialization.py:418\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 418\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'c:/temp/MarSpheare'"
     ]
    }
   ],
   "source": [
    "\n",
    "X = [str(i) for i in testCorpus['sentence_source'].values]       # comma separate the sentences in the pandas column 'sentence_source'\n",
    "model = torch.load(SavePath)\n",
    "tokenizer = BertTokenizer.from_pretrained(model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use nvidia cuda 12.1 -> 12.2 is not supported yet!\n",
    "\n",
    "tokenized_text = tokenizer(X, padding=True, truncation=True, max_length=100, return_tensors='pt')\n",
    "batch_size = 16\n",
    "unseen_data_loader = torch.utils.data.DataLoader(tokenized_text['input_ids'], batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "predicted_authors = []\n",
    "with torch.no_grad():\n",
    "    for batch in unseen_data_loader:\n",
    "        batch = batch.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        outputs = model(batch)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        predicted_authors.extend(predicted_labels.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
